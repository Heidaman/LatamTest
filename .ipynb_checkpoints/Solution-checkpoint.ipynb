{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota:**\n",
    "Si es la primera vez que usas este notebook descomenta y ejecuta la siguiente celda, o instala de tu manera preferida los siguientes paquetes.\n",
    "\n",
    "* matplotlib==3.5.2\n",
    "* numpy==1.22.4\n",
    "* pandas==1.4.2\n",
    "* scikit-learn==1.1.1\n",
    "* tqdm==4.64.0\n",
    "* seaborn==0.10.1\n",
    "* missingno==0.4.2\n",
    "* dill==0.3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install matplotlib==3.5.2 numpy==1.22.4 pandas==1.4.2 scikit-learn==1.1.1 tqdm==4.64.0 seaborn==0.10.1 missingno==0.4.2 dill==0.3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import glob\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "import dill as pickle\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "\n",
    "from datetime import date, datetime, time\n",
    "from os.path import dirname, exists\n",
    "from tqdm import tqdm\n",
    "from time import perf_counter, sleep\n",
    "from humanfriendly import format_timespan\n",
    "from pandas.api.types import is_numeric_dtype  \n",
    "tqdm.pandas()\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # Suppress all warnings\n",
    "plt.style.use('ggplot')\n",
    "pd.set_option('display.max_rows', 1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if exists('dataset_SCL.csv'):\n",
    "    dataset = pd.read_csv('dataset_SCL.csv', sep = \",\", decimal = \".\", na_values = \"NA\", encoding='utf8', low_memory = False)\n",
    "\n",
    "dataset['Fecha-I'] = pd.to_datetime(dataset['Fecha-I'])\n",
    "dataset['Fecha-O'] = pd.to_datetime(dataset['Fecha-O'])\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for col in dataset:\n",
    "    print(\"Valores Unicos de la Variable \", col)\n",
    "    print(dataset[col].unique())\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" \\nDataset shape: \\n\\n\", \n",
    "      dataset.shape)\n",
    "print(\" \\nCount total NaN at each column in the dataset : \\n\\n\", \n",
    "      dataset.isnull().sum()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Limpieza de Datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Información Dataset\")\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset.isnull().values.any():\n",
    "    msno.matrix(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dropna(inplace=True)\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogramgraph(data):\n",
    "    fig = plt.figure(figsize = (20,15))\n",
    "    ax = fig.gca()\n",
    "    data.hist(ax = ax, alpha=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogramgraph(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot(data):\n",
    "    data.plot.box(figsize = (15, 10), rot = 90, grid = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlationgraph(data):\n",
    "    f = plt.figure(figsize=(15, 10))\n",
    "    plt.matshow(data.corr(), fignum=f.number)\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "    for (i, j), z in np.ndenumerate(data.corr()):\n",
    "        plt.text(j, i, '{:0.2f}'.format(z), ha='center', va='center',\n",
    "                bbox=dict(boxstyle='round', facecolor='white', edgecolor='0.3'))\n",
    "    plt.xticks(range(data.select_dtypes(['number']).shape[1]), data.select_dtypes(['number']).columns, fontsize=14, rotation=45)\n",
    "    plt.yticks(range(data.select_dtypes(['number']).shape[1]), data.select_dtypes(['number']).columns, fontsize=14)\n",
    "    cb = plt.colorbar()\n",
    "    cb.ax.tick_params(labelsize=14)\n",
    "    plt.title('Correlation Matrix', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlationgraph2(data, scale):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    sns.set(font_scale = scale)\n",
    "    sns.heatmap(data.corr(), annot=True, cmap=\"YlGnBu\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlationgraph2(dataset, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generando archivo synthetic_features.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporadas(row):\n",
    "    datetime_obj = datetime.strptime(str(row), '%Y-%m-%d %H:%M:%S')\n",
    "    my_date = datetime_obj.date()\n",
    "    \n",
    "    boundarydict = {\"Si\": [(date(my_date.year, 1, 1), date(my_date.year, 3, 3)),\n",
    "                           (date(my_date.year, 7, 15), date(my_date.year, 7, 31)),\n",
    "                           (date(my_date.year, 9, 11), date(my_date.year, 9, 30)),\n",
    "                           (date(my_date.year, 12, 15), date(my_date.year, 12, 31))],\n",
    "                    \"No\": [(date(my_date.year, 3, 4), date(my_date.year, 7, 14)),\n",
    "                           (date(my_date.year, 8, 1), date(my_date.year, 9, 10)),\n",
    "                           (date(my_date.year, 10, 1), date(my_date.year, 12, 14))]}\n",
    "    \n",
    "    for retval, boundaries in boundarydict.items():\n",
    "        if any(a <= my_date <= b for a, b in boundaries):\n",
    "            return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def periodo(row):\n",
    "    datetime_obj = datetime.strptime(str(row), '%Y-%m-%d %H:%M:%S')\n",
    "    my_time = datetime_obj.time()\n",
    "    \n",
    "    boundarydict = {\"mañana\": [(time(5, 0), time(11, 59))],\n",
    "                    \"tarde\": [(time(12, 0), time(18, 59))],\n",
    "                    \"noche\": [(time(19, 0), time(23, 59)),\n",
    "                              (time(0, 0), time(4, 59))]}\n",
    "    \n",
    "    for retval, boundaries in boundarydict.items():\n",
    "        if any(a <= my_time <= b for a, b in boundaries):\n",
    "            return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_features = pd.DataFrame(columns=['temporada_alta', 'dif_min', 'atraso_15', 'periodo_dia'], \n",
    "                                  index = dataset.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_features['temporada_alta'] = dataset['Fecha-I'].progress_apply(temporadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_features['dif_min'] = dataset['Fecha-O'] - dataset['Fecha-I']\n",
    "synthetic_features['dif_min'] = synthetic_features['dif_min'] / np.timedelta64(1,'m')\n",
    "synthetic_features['dif_min'][synthetic_features['dif_min'] < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_features['atraso_15'] = synthetic_features['dif_min'].progress_apply(lambda x: 1 if x > 15.0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_features['periodo_dia'] = dataset['Fecha-I'].progress_apply(periodo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_features.to_csv(\"synthetic_features.csv\", sep=',', decimal = \".\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in synthetic_features:\n",
    "    print(\"Valores Unicos de la Variable \", col)\n",
    "    print(synthetic_features[col].unique())\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tasa de atraso**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación observamos la tasas de retraso usando como variables de medición distintos atributos del conjunto de datos. Se puede ver que....\n",
    "\n",
    "Con base a esto esperamos que las variables de... sean las de mayor aporte al momento de predecir retrasos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tasadeatraso(df, col, filas, decimales):\n",
    "    print(round(df.groupby([col])[col].count()/filas, decimales))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atraso_synthetic_features = synthetic_features.loc[synthetic_features['atraso_15'] == 1]\n",
    "atraso_dataset = dataset.loc[atraso_synthetic_features.index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"tasa de atraso/destino origen\")\n",
    "tasadeatraso(df = atraso_dataset, col = 'Des-I', \n",
    "             filas = dataset.shape[0], decimales = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"tasa de atraso/destino operación\")\n",
    "tasadeatraso(df = atraso_dataset, col = 'Des-O', \n",
    "             filas = dataset.shape[0], decimales = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"tasa de atraso/aerolinea\")\n",
    "tasadeatraso(df = atraso_dataset, col = 'OPERA', \n",
    "             filas = dataset.shape[0], decimales = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"tasa de atraso/mes\")\n",
    "tasadeatraso(df = atraso_dataset, col = 'MES', \n",
    "             filas = dataset.shape[0], decimales = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"tasa de atraso/día\")\n",
    "tasadeatraso(df = atraso_dataset, col = 'DIANOM', \n",
    "             filas = dataset.shape[0], decimales = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"tasa de atraso/tipo de vuelo\")\n",
    "tasadeatraso(df = atraso_dataset, col = 'TIPOVUELO', \n",
    "             filas = dataset.shape[0], decimales = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"tasa de atraso/temporada\")\n",
    "tasadeatraso(df = atraso_synthetic_features, col = 'temporada_alta', \n",
    "             filas = synthetic_features.shape[0], decimales = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generación Algoritmo de Predicción**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorizamos las variables no numericas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_cats(df):\n",
    "    cats = []\n",
    "    for col in df.columns:\n",
    "        if is_numeric_dtype(df[col]) or \"Fecha\" in col:\n",
    "            pass\n",
    "        else:\n",
    "            cats.append(col)\n",
    "            \n",
    "    for col in cats:\n",
    "        df[col] = df[col].astype('category').cat.codes\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_highly_correlated(data, threshold):\n",
    "    col_corr = set() # Set of all the names of deleted columns\n",
    "    corr_matrix = data.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if (corr_matrix.iloc[i, j] >= threshold) and (corr_matrix.columns[j] not in col_corr):\n",
    "                colname = corr_matrix.columns[i] # getting the name of column\n",
    "                col_corr.add(colname)\n",
    "                if colname in data.columns:\n",
    "                    del data[colname] # deleting the column from the data\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probatraso(row):\n",
    "    atraso = round((row.dif_min * 100 / 15), 3)\n",
    "    if atraso >= 100.000:\n",
    "        return 100.000\n",
    "    else:\n",
    "        return atraso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def savemodel(model, name, verbose):\n",
    "    if verbose:\n",
    "        print(\"Saving model:\", name)\n",
    "    if not os.path.isdir('Models'):\n",
    "        os.mkdir(\"Models\")\n",
    "    with open(name, 'wb') as f:\n",
    "        pickle.dump(model, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelraining(data, modelos, verbose):\n",
    "    startf = perf_counter()\n",
    "    X = data.drop(\"Probabilidad_Atraso\", axis = 1)\n",
    "    y = data['Probabilidad_Atraso']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test\n",
    "        \n",
    "    for modelo in modelos:\n",
    "        clase = 1\n",
    "        if modelo == \"linear\":\n",
    "            model = linear_model.LinearRegression()\n",
    "        elif modelo == \"Ridge\":\n",
    "            model = linear_model.Ridge(alpha=.5)\n",
    "        elif modelo == \"Lasso\":\n",
    "            model = linear_model.Lasso(alpha=.1)\n",
    "        elif modelo == \"BayesianRidge\":\n",
    "            model = linear_model.BayesianRidge()\n",
    "        elif modelo == \"SVM\":\n",
    "            model = svm.SVR()\n",
    "        elif modelo == \"Tree\":\n",
    "            model = tree.DecisionTreeRegressor()\n",
    "        elif modelo == \"RF\":\n",
    "            model = RandomForestRegressor(random_state=1)\n",
    "        elif modelo == \"GBR\":\n",
    "            model = GradientBoostingRegressor(random_state=1)\n",
    "        elif modelo == \"VR\":\n",
    "            reg1 = GradientBoostingRegressor(random_state=1)\n",
    "            reg2 = RandomForestRegressor(random_state=1)\n",
    "            reg3 = linear_model.LinearRegression()\n",
    "            model = VotingRegressor(estimators=[('GBR', reg1), ('RF', reg2), ('linear', reg3)])\n",
    "        elif modelo == \"KNN\":\n",
    "            model = KNeighborsRegressor(n_neighbors=20, metric='euclidean')\n",
    "        elif modelo == \"MLP\":\n",
    "            model = MLPRegressor(random_state=1, max_iter=500)\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "            \n",
    "        if verbose:\n",
    "            print(modelo + \" r2_score:\",metrics.r2_score(y_test, y_pred))\n",
    "            print(modelo + \" MAE:\",metrics.mean_absolute_error(y_test, y_pred))\n",
    "            print(modelo + \" MSE:\",metrics.mean_squared_error(y_test, y_pred))\n",
    "            #print(modelo + \" MSLE:\",metrics.mean_squared_log_error(y_test, y_pred))\n",
    "            #print(modelo + \" MAPE:\",metrics.mean_absolute_percentage_error(y_test, y_pred))\n",
    "            #print(modelo + \" MedAE:\",metrics.median_absolute_error(y_test, y_pred))\n",
    "            #print(modelo + \" Max Error:\",metrics.max_error(y_test, y_pred))\n",
    "            #print(modelo + \" EVS:\",metrics.explained_variance_score(y_test, y_pred))\n",
    "        \n",
    "        savemodel(model, \"Models/\"+ modelo +\"_PrData.pkl\", verbose)\n",
    "        if verbose:\n",
    "            print(\"-----------------------------------------------------------------------------\")\n",
    "            print(\"\")\n",
    "        \n",
    "    if verbose == True:\n",
    "        print(\"--Took\", format_timespan(perf_counter() - startf), \"to process the file with the selected models.\")\n",
    "        print(\"-----------------------------------------------------------------------------\")\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = convert_cats(dataset.copy())\n",
    "dataset2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2.drop('Ori-I', axis=1, inplace=True)\n",
    "dataset2.drop('Ori-O', axis=1, inplace=True)\n",
    "dataset2.drop('SIGLAORI', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_features2 = convert_cats(synthetic_features.copy())\n",
    "synthetic_features2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "correlationgraph2(dataset2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogramgraph(dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "correlationgraph2(synthetic_features2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogramgraph(synthetic_features2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allDataset = pd.concat([dataset2, synthetic_features2], axis=1)\n",
    "allDataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlationgraph2(allDataset, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allDataset.drop('Fecha-I', axis=1, inplace=True)\n",
    "allDataset.drop('Fecha-O', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vif(data, cols):\n",
    "    if not cols:\n",
    "        vif = pd.DataFrame()\n",
    "        vif[\"features\"] = allDataset.columns\n",
    "        vif[\"vif_Factor\"] = [variance_inflation_factor(allDataset.values, i) for i in range(allDataset.shape[1])]\n",
    "    else:\n",
    "        X = allDataset.drop(cols, axis=1)\n",
    "        vif = pd.DataFrame()\n",
    "        vif[\"features\"] = X.columns\n",
    "        vif[\"vif_Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    print(vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collist = []\n",
    "vif(allDataset, collist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collist = [\"Des-O\", \"Des-I\"]\n",
    "vif(allDataset, collist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collist = [\"Vlo-I\", \"Vlo-O\", \"Des-O\", \"Des-I\"]\n",
    "vif(allDataset, collist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collist = [\"Vlo-I\", \"Vlo-O\", \"Des-O\", \"Des-I\", \"Emp-O\", \"Emp-I\"]\n",
    "vif(allDataset, collist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collist = [\"Vlo-I\", \"Vlo-O\", \"Des-O\", \"Des-I\", \"Emp-O\", \"Emp-I\", \"AÑO\"]\n",
    "vif(allDataset, collist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allDataset.drop(collist, inplace = True, axis=1)\n",
    "correlationgraph2(allDataset, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allDataset = delete_highly_correlated(data = allDataset, threshold = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlationgraph2(allDataset, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "allDataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allDataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allDataset['Probabilidad_Atraso'] = allDataset.progress_apply(probatraso, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "allDataset.drop('atraso_15', axis=1, inplace=True)\n",
    "allDataset.drop('dif_min', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestModels = [\"linear\",\"Ridge\",\"Lasso\",\"BayesianRidge\",\"SVM\",\"Tree\",\"RF\",\"GBR\",\"VR\",\"KNN\", \"MLP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "modelraining(data = allDataset, modelos = TestModels, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
